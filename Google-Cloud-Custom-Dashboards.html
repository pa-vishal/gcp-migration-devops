<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Google Cloud Custom Dashboards with BigQuery & Looker Studio</title>

    <link rel="stylesheet" href="styles.css">
</head>

<body class="markdown-body">
    <h1>Google Cloud Custom Dashboards: BigQuery & Looker Studio</h1>
    <div class="summary-block">
        This page guides you through building custom dashboards in Google Cloud using BigQuery and Looker Studio, including log routing, data preparation, visualization, and cost considerations.
    </div>

    <p>This guide will walk you through creating custom dashboards in Google Cloud using BigQuery and Looker Studio to
        gain insights from your logs. We'll also provide a sample cost breakdown for such a setup.</p>

    <h2>Phase 1: Route Logs to BigQuery</h2>

    <p>The first step is to get your log data from Cloud Logging into BigQuery, which serves as our robust data
        warehouse.</p>

    <h3>1. Enable Logging and Create a Log Sink:</h3>
    <ul>
        <li>Go to the <strong>Cloud Logging</strong> console in Google Cloud.</li>
        <li>Navigate to <strong>Logs Router</strong>.</li>
        <li>Click <strong>Create Sink</strong>.</li>
        <li><strong>Name your sink</strong> and provide a description.</li>
        <li><strong>Choose the logs to include:</strong> This is crucial. Use the Log Explorer to build a query that
            filters for the specific logs you want to analyze. For example, you might filter by
            <code>resource.type</code>, <code>logName</code>, <code>severity</code>, or specific
            <code>jsonPayload</code> fields.</li>
        <li><strong>Select BigQuery Dataset</strong> as the sink destination.</li>
        <li><strong>Create a new BigQuery dataset</strong> if you don't have one, or select an existing one. It's
            recommended to create a dedicated dataset for your log data.</li>
        <li>Ensure that you are using <strong>partitioned tables</strong> in BigQuery for your log data. This
            significantly improves query performance and reduces costs by only scanning relevant partitions. The sink
            will typically create a table (e.g., <code>requests</code>) within your chosen dataset.</li>
        <li>Click <strong>Create Sink</strong>. This will start routing new logs matching your filter to the specified
            BigQuery table.</li>
    </ul>

    <h3>2. Verify Log Ingestion:</h3>
    <ul>
        <li>Go to the <strong>BigQuery</strong> console.</li>
        <li>Navigate to your log dataset and the newly created table (e.g., <code>requests</code>).</li>
        <li>Query the table to ensure logs are being ingested correctly and the data structure is as expected.</li>
    </ul>

    <hr>

    <h2>Phase 2: Prepare Your Data in BigQuery (Optional but Recommended)</h2>

    <p>While you can connect Looker Studio directly to the raw log table, it's often beneficial to transform and refine
        your data in BigQuery first. This can involve:</p>

    <h3>1. Creating Views:</h3>
    <ul>
        <li>Instead of querying the raw log table directly, create BigQuery <strong>views</strong> that select only the
            necessary columns and apply any required transformations (e.g., extracting specific fields from JSON
            payloads, converting data types, aggregating data). This simplifies queries in Looker Studio and can improve
            performance.</li>
        <li>Example: If your logs have a <code>jsonPayload</code> field with nested data, you can use JSON functions in
            BigQuery SQL to extract specific values into separate columns.</li>
    </ul>

    <h3>2. Aggregating Data:</h3>
    <ul>
        <li>For performance and cost efficiency, especially with large log volumes, consider creating <strong>aggregated
                tables or materialized views</strong> in BigQuery. For example, if you want to track daily error counts,
            you can create a view that aggregates errors by day rather than querying all raw logs every time.</li>
    </ul>

    <h3>3. Partitioning and Clustering:</h3>
    <ul>
        <li>Ensure your BigQuery tables are appropriately <strong>partitioned and clustered</strong>. This is especially
            important for log data, which is time-series in nature. Partitioning by date is common and highly effective
            for log analysis.</li>
    </ul>

    <hr>

    <h2>Phase 3: Create Dashboards in Looker Studio</h2>

    <h3>1. Connect Looker Studio to BigQuery:</h3>
    <ul>
        <li>Go to <strong>Looker Studio</strong> (formerly Google Data Studio).</li>
        <li>Click <strong>Create</strong> &gt; <strong>Report</strong>.</li>
        <li>In the "Add data to report" panel, select the <strong>BigQuery connector</strong>.</li>
        <li><strong>Authorize</strong> the connection to your Google Cloud project if prompted.</li>
        <li>Choose your <strong>Google Cloud Project</strong>, then the <strong>BigQuery Dataset</strong> where your
            logs are stored (or your views/aggregated tables).</li>
        <li>Select the <strong>table or view</strong> you want to use as your data source. You can also use a
            <strong>Custom Query</strong> here if you want to write specific SQL to pull data. For complex analysis,
            it's often better to define views in BigQuery and connect to those.</li>
        <li>Click <strong>Add</strong>. Your data source will be added to the report.</li>
    </ul>

    <h3>2. Configure the Data Source:</h3>
    <ul>
        <li>Looker Studio will display the fields from your BigQuery table/view, categorizing them as dimensions
            (typically text or date fields) and metrics (numerical fields).</li>
        <li>Review and adjust the <strong>data types and aggregation methods</strong> for your fields as needed. For
            example, if a numerical field is incorrectly classified as text, change its type.</li>
    </ul>

    <h3>3. Build Your Dashboard:</h3>
    <ul>
        <li><strong>Add charts and visualizations:</strong> In the Looker Studio toolbar, click <strong>Add a
                chart</strong> and select the type of visualization you want (e.g., time series chart for trends, bar
            chart for counts, table for detailed log entries, pie chart for distribution).</li>
        <li><strong>Drag and drop fields:</strong> Drag fields from the "Data" pane to the "Dimensions" and "Metrics"
            sections of your chosen chart's properties panel.
            <ul>
                <li><strong>Dimensions:</strong> Used for grouping and categorizing data (e.g., <code>timestamp</code>,
                    <code>logName</code>, <code>severity</code>, <code>resource.type</code>, extracted error codes).
                </li>
                <li><strong>Metrics:</strong> Used for measuring values (e.g., <code>recordCount</code>,
                    <code>averageDuration</code>, <code>sumOfErrors</code>).</li>
            </ul>
        </li>
        <li><strong>Apply Filters:</strong> Add filters to your dashboard or individual charts to focus on specific time
            ranges, log levels, or resource types.</li>
        <li><strong>Add Controls:</strong> Use "Add a control" to include interactive elements like date range
            selectors, dropdown lists for log names or severity levels, and text input boxes for searching specific
            keywords in log messages.</li>
        <li><strong>Design and Layout:</strong> Arrange your charts and controls on the canvas to create a clear and
            insightful dashboard. Customize colors, fonts, and styling for better readability.</li>
    </ul>

    <h3>4. Share Your Dashboard:</h3>
    <ul>
        <li>Once your dashboard is complete, click <strong>Share</strong> in the top right corner.</li>
        <li>You can invite specific users by email address or generate a shareable link.</li>
        <li>Specify whether recipients can view or edit the report.</li>
    </ul>

    <div class="note">
        <h3>Key Considerations for Logs Analysis:</h3>
        <ul>
            <li><strong>Cost Management:</strong> BigQuery charges for data storage and query processing. By routing
                only necessary logs and using partitioned/clustered tables and efficient queries, you can minimize
                costs. Creating aggregated views can also significantly reduce query costs in Looker Studio.</li>
            <li><strong>Data Freshness:</strong> Looker Studio can refresh data from BigQuery at various intervals.
                Consider how real-time your insights need to be. For critical operational dashboards, you might need
                more frequent refreshes.</li>
            <li><strong>Granularity:</strong> Decide on the level of detail you need in your logs. Do you need
                individual log entries, or are aggregated counts sufficient for your dashboards? This will influence
                your BigQuery schema and query design.</li>
            <li><strong>Security:</strong> Ensure proper IAM roles are set up for the log sink and for users accessing
                the BigQuery dataset and Looker Studio reports.</li>
            <li><strong>Logs-based Metrics (Cloud Monitoring):</strong> For simple counts or specific value extraction
                from logs, you might also consider using Cloud Monitoring's logs-based metrics. These can be visualized
                directly in Cloud Monitoring dashboards without needing BigQuery or Looker Studio, but they have
                limitations for complex analysis or combining with other data sources. For more in-depth insights and
                combining log data with other metrics, BigQuery and Looker Studio are the preferred tools.</li>
        </ul>
    </div>

    <hr>

    <h2>Sample Cost Breakdown</h2>

    <div class="disclaimer">
        <h3>Important Disclaimers:</h3>
        <ul>
            <li><strong>Estimates Only:</strong> These are <em>estimates</em> and actual costs will vary significantly
                based on your specific usage.</li>
            <li><strong>Region-Specific Pricing:</strong> Prices differ by Google Cloud region. The estimates below use
                common US multi-region prices as of mid-2025.</li>
            <li><strong>Free Tiers:</strong> Google Cloud offers free tiers for many services (e.g., initial GBs of
                storage, initial TBs of queries). These examples assume usage <em>beyond</em> the free tier.</li>
            <li><strong>Optimization is Key:</strong> Effective cost management involves careful log filtering, data
                partitioning/clustering, and efficient BigQuery queries.</li>
        </ul>
    </div>

    <h3>Scenario: Medium-Sized Web Application</h3>
    <ul>
        <li><strong>Log Volume:</strong> 500 GB of logs ingested into Cloud Logging per month.</li>
        <li><strong>Log Exported to BigQuery:</strong> 300 GB of relevant logs exported to BigQuery per month after
            filtering (the other 200 GB are less critical and discarded or stored in Cloud Logging only for a short
            default retention).</li>
        <li><strong>BigQuery Data Stored:</strong>
            <ul>
                <li>Active storage: 3 TB (for recent data, views, and aggregated tables).</li>
                <li>Long-term storage: 5 TB (for older, less frequently accessed log data).</li>
            </ul>
        </li>
        <li><strong>BigQuery Query Volume:</strong>
            <ul>
                <li>Daily dashboard refreshes: 1 TB of data scanned per month for Looker Studio queries.</li>
                <li>Ad-hoc analysis by engineers: 0.5 TB of data scanned per month.</li>
            </ul>
        </li>
        <li><strong>Looker Studio Usage:</strong> Free tier (self-service). No Looker Studio Pro.</li>
    </ul>

    <h3>Cost Breakdown Categories:</h3>

    <h4>1. Cloud Logging (Log Ingestion & Export)</h4>
    <ul>
        <li><strong>Ingestion:</strong> $0.50 per GiB (after 50 GiB free tier per project per month).</li>
        <li>Calculation: (500 GiB - 50 GiB free) * $0.50/GiB = <strong>$225.00</strong></li>
        <li>**Log Router (Export to BigQuery):** Generally free. Cost is incurred at the destination.</li>
        <li>**Total Cloud Logging Cost (relevant for this setup): $225.00**</li>
    </ul>

    <h4>2. BigQuery (Storage and Querying)</h4>
    <ul>
        <li><strong>Data Storage:</strong>
            <ul>
                <li>**Active Storage:** $0.020 per GiB per month (after 10 GiB free tier per month).</li>
                <li>Calculation: (3000 GiB - 10 GiB free) * $0.020/GiB = $59.80</li>
                <li>**Long-Term Storage:** (Data not modified for 90 days, automatically transitions) $0.010 per GiB per
                    month.</li>
                <li>Calculation: 5000 GiB * $0.010/GiB = $50.00</li>
                <li>**Total BigQuery Storage Cost: $109.80**</li>
            </ul>
        </li>
        <li><strong>Querying (On-Demand Pricing):</strong> $5.00 per TiB (after 1 TiB free tier per month).</li>
        <li>Calculation:
            <ul>
                <li>Total Query Volume: 1 TB (Looker Studio) + 0.5 TB (Ad-hoc) = 1.5 TB</li>
                <li>(1.5 TiB - 1 TiB free) * $5.00/TiB = 0.5 TiB * $5.00/TiB = <strong>$2.50</strong></li>
            </ul>
        </li>
        <li>**Data Ingestion (Streaming Inserts, if used):** $0 (assuming log sink batch loading).</li>
        <li>**Total BigQuery Cost: $109.80 (Storage) + $2.50 (Querying) = $112.30**</li>
    </ul>

    <h4>3. Looker Studio</h4>
    <ul>
        <li><strong>Self-service BI:</strong> No charge.</li>
        <li>**Total Looker Studio Cost: $0.00** (unless using Looker Studio Pro)</li>
    </ul>

    <h3>Estimated Total Monthly Cost for this Sample Setup:</h3>
    <table>
        <thead>
            <tr>
                <th>Service</th>
                <th>Estimated Monthly Cost</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>Cloud Logging Ingestion</td>
                <td>$225.00</td>
            </tr>
            <tr>
                <td>BigQuery Storage</td>
                <td>$109.80</td>
            </tr>
            <tr>
                <td>BigQuery Querying</td>
                <td>$2.50</td>
            </tr>
            <tr>
                <td>Looker Studio</td>
                <td>$0.00</td>
            </tr>
            <tr>
                <td><strong>Overall Estimated Monthly Cost</strong></td>
                <td><strong>$337.30</strong></td>
            </tr>
        </tbody>
    </table>

    <h3>How to Control and Optimize Costs:</h3>
    <ul>
        <li>**Cloud Logging:**
            <ul>
                <li><strong>Filter aggressively with Log Sinks:</strong> Only send logs to BigQuery that you *really*
                    need for analysis. This is the biggest lever for reducing ingestion costs.</li>
                <li><strong>Adjust Log Retention:</strong> Don't keep logs in Cloud Logging buckets longer than
                    necessary if they're already exported.</li>
            </ul>
        </li>
        <li>**BigQuery:**
            <ul>
                <li><strong>Partitioning and Clustering:</strong> Essential for log data. It allows BigQuery to scan
                    only relevant partitions, drastically reducing query costs.</li>
                <li><strong>Optimize Queries:</strong> <code>SELECT</code> only necessary columns and use effective
                    <code>WHERE</code> clauses.</li>
                <li><strong>Create Views/Aggregated Tables:</strong> Pre-calculate frequently queried aggregated data.
                </li>
                <li><strong>Data Lifecycle Management:</strong> Leverage BigQuery's long-term storage or export to Cloud
                    Storage for archival.</li>
                <li><strong>On-Demand vs. Flat-Rate:</strong> For high query volumes, investigate BigQuery's flat-rate
                    pricing.</li>
            </ul>
        </li>
        <li>**Looker Studio:**
            <ul>
                <li><strong>Leverage BigQuery Views:</strong> Use optimized BigQuery views as your Looker Studio data
                    source.</li>
                <li><strong>Caching:</strong> Looker Studio's caching can reduce direct BigQuery query costs.</li>
                <li><strong>Refresh Rate:</strong> Set appropriate refresh rates for your dashboards; less frequent
                    refreshes mean fewer BigQuery queries.</li>
            </ul>
        </li>
    </ul>

    <p>By understanding these components and applying optimization strategies, you can effectively manage the costs
        associated with your Google Cloud logging and dashboarding solution.</p>

    <div class="watermark">Vishal Patil</div>
</body>

</html>